{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5bcdf1a-2879-4374-8b9a-83453a5254fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import skew, kurtosis, norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c01b3da-ef70-4c32-a532-05311547214b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dollar_df = pd.read_csv('../data/processed_sp500_futures_dollar.csv')\n",
    "dollar_df['datetime'] = pd.to_datetime(dollar_df['datetime'], format='mixed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8913b167-ce9f-4bc9-94ef-4281b14f618e",
   "metadata": {},
   "source": [
    "#### Compute HHI index on positive and negative returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b7b9698-8792-4616-884b-e854159f446a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hhi(returns):\n",
    "    r_plus = returns[returns > 0]\n",
    "    r_minus = returns[returns < 0]\n",
    "    w_plus = r_plus / r_plus.sum()\n",
    "    w_minus = r_minus / r_minus.sum()\n",
    "    n_plus = len(r_plus)\n",
    "    n_minus = len(r_minus)\n",
    "    \n",
    "    hhi_plus = (sum(w_plus**2) - 1/n_plus) / (1 - 1/n_plus)\n",
    "    hhi_minus = (sum(w_minus**2) - 1/n_minus) / (1 - 1/n_minus)\n",
    "\n",
    "    return hhi_plus, hhi_minus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffd5baf8-cc82-4f1b-bf22-8a43b6f476a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HHI of positive returns are 0.0000047739\n",
      "HHI of negative returns are 0.0000058734\n"
     ]
    }
   ],
   "source": [
    "hhi_plus, hhi_minus = compute_hhi(dollar_df.label_returns)\n",
    "print(\"HHI of positive returns are {:.10f}\".format(hhi_plus))\n",
    "print(\"HHI of negative returns are {:.10f}\".format(hhi_minus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866d9437-9186-4a76-95c1-ecd73994e288",
   "metadata": {},
   "source": [
    "#### Compute 95-percentile DD and TuW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67f2dae4-47cf-4279-854b-753135e9d93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute all the drawdowns from high watermarks\n",
    "# Then choose the 95-percentile value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bf24ddd-f661-47f2-aeae-6e70c82c4bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_drawdown_timeunderwater(prices, datetime):\n",
    "    high_water_mark = prices.cummax()\n",
    "    dd = pd.DataFrame({'datetime': datetime, 'price': prices, 'high_water_mark': high_water_mark})\n",
    "    dd = dd[dd.high_water_mark > dd.price]\n",
    "    dd = dd.groupby('high_water_mark').agg({'price': 'mean', 'datetime': lambda x: x.iloc[-1] - x.iloc[0]}).reset_index()\n",
    "    dd['drawdown'] = dd.high_water_mark - dd.price\n",
    "\n",
    "    return dd.drawdown, dd.datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f7b8454-ee1d-46f7-a846-4765d1253637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95-percentile draw down is: 8.865270570793323\n",
      "95-percentile time under water is: 6 days 00:39:09.500000\n"
     ]
    }
   ],
   "source": [
    "drawdown, timeunderwater = compute_drawdown_timeunderwater(dollar_df.close, dollar_df.datetime)\n",
    "\n",
    "drawdown_95_percentile = np.percentile(drawdown, 95)\n",
    "time_under_water_95_percentile = pd.Timedelta(np.percentile(timeunderwater, 95))\n",
    "\n",
    "print(\"95-percentile draw down is: {}\".format(drawdown_95_percentile))\n",
    "print(\"95-percentile time under water is: {}\".format(time_under_water_95_percentile))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2f44e4-7b29-4231-9bcc-2a4d9873584d",
   "metadata": {},
   "source": [
    "#### Compute Annualized Average Return, Average Returns from Hits / Misses, and Annualized SR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac7e1cb0-c145-4eab-b64b-ff8926e6445b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_annualized_ave_return(datetimes, prices):\n",
    "    total_return = (prices.iloc[-1] - prices.iloc[0]) / prices.iloc[0] - 1\n",
    "    year_count = (datetimes.iloc[-1] - datetimes.iloc[0]).days // 365\n",
    "    annualized_return = (1+total_return)**(1/year_count) - 1\n",
    "    return annualized_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20048816-dec0-4ce4-85e8-b6bf0ce367ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Annualized Return is: 2.70%\n"
     ]
    }
   ],
   "source": [
    "annualized_return = compute_annualized_ave_return(dollar_df.datetime, dollar_df.close)\n",
    "print(\"The Annualized Return is: {:.2f}%\".format(annualized_return * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5404e661-b19c-46ac-a9f8-5d4d2d0a3070",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ave_return_hit_miss(returns, prices):\n",
    "    hit_idx = returns > 0\n",
    "    hit_avg_return = (returns[hit_idx] / prices[hit_idx]).mean()\n",
    "    \n",
    "    miss_idx = returns < 0\n",
    "    miss_avg_return = (returns[miss_idx] / prices[miss_idx]).mean()\n",
    "\n",
    "    return hit_avg_return, miss_avg_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebc45aab-5021-4a1d-b8a1-8a1b90b070d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average return from hits: 0.32%\n",
      "Average return from misses: -0.34%\n"
     ]
    }
   ],
   "source": [
    "hit_avg_return, miss_avg_return = compute_ave_return_hit_miss(dollar_df.label_returns, dollar_df.close)\n",
    "\n",
    "print(\"Average return from hits: {:.2f}%\".format(hit_avg_return * 100))\n",
    "print(\"Average return from misses: {:.2f}%\".format(miss_avg_return * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65258ed7-e791-4204-b680-df8581dd87c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annual_sharpe(returns, prices, datetimes):\n",
    "    return_rates = returns / prices\n",
    "    sharpe_ratio = return_rates.mean() / return_rates.std()\n",
    "    day_count = (datetimes.iloc[-1] - datetimes.iloc[0]).days\n",
    "    annualized_sharpe_ratio = np.sqrt(day_count) * sharpe_ratio\n",
    "    return annualized_sharpe_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d964505c-c644-425e-816f-c61b2b1bf794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annualized Sharpe Ratio is 0.44\n"
     ]
    }
   ],
   "source": [
    "annual_sharpe_ratio = annual_sharpe(dollar_df.label_returns, dollar_df.close, dollar_df.datetime)\n",
    "print(\"Annualized Sharpe Ratio is {:.2f}\".format(annual_sharpe_ratio))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c8d041-312c-4983-8ad9-6d058900d8e6",
   "metadata": {},
   "source": [
    "#### Compute Information Ratio, where the benchmark is the risk-free rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bded57c-68d6-430d-9d9c-308bd9fcaabc",
   "metadata": {},
   "source": [
    "##### Assuming the risk-free rate is 80% of the mean of the portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5d21dc2-c6b4-4f2f-97f6-b2de5bb964b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_ratio(returns, datetimes, rf_rate):\n",
    "    excess_return = dollar_df.label_returns - rf_rate\n",
    "    day_count = (datetimes.iloc[-1] - datetimes.iloc[0]).days\n",
    "    information_ratio = excess_return.mean() / excess_return.std() * np.sqrt(day_count)\n",
    "    return information_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4425aac-1368-473e-9b0c-b83ecdf476c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Information Ratio is -0.0006002150\n"
     ]
    }
   ],
   "source": [
    "rf_rate = dollar_df.label_returns.mean() * 0.8\n",
    "information_ratio = information_ratio(dollar_df.label_returns, dollar_df.datetime, rf_rate)\n",
    "print(\"The Information Ratio is {:.10f}\".format(information_ratio))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84385264-0e7c-4d20-ab34-f1e057084c4a",
   "metadata": {},
   "source": [
    "#### Compute the Probabilistic Sharpe Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da32c4c7-cc9d-4d3f-b310-878213c69d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_sharpe_ratio(returns, hyp_sr):\n",
    "    obs_sr = returns.mean() / returns.std()\n",
    "    T = len(returns)\n",
    "    y_3 = skew(returns)\n",
    "    y_4 = kurtosis(returns)\n",
    "    z_score = (obs_sr-hyp_sr) * np.sqrt(T-1) / np.sqrt(1 - y_3*obs_sr + 1/4*(y_4-1)*obs_sr**2)\n",
    "    return norm().cdf(z_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95755e94-b7a0-472a-8cf0-09baa8b20133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2726537651302702"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_sharpe_ratio(dollar_df.label_returns, 0.0005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26979f6f-8117-4ce3-92d9-a4ee4cc811cb",
   "metadata": {},
   "source": [
    "#### Compute DSR, where we assume there were 100 trials, and the variance of the trials’ SR was 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aecc4ce8-3a3b-43db-bde8-0911d0171542",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deflated_sr(N, sr_variance):\n",
    "    norm_dist = norm()\n",
    "    return np.sqrt(sr_variance) * ((1-np.euler_gamma)*norm_dist.ppf(1-1/N) + np.euler_gamma*(norm_dist.ppf(1-1/N*1/np.e)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ba8f257-c129-402a-b902-ade1f358bfc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7894064662732079"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deflated_sr(100, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a16f23c-9d45-475c-a511-4be6d26b5f7e",
   "metadata": {},
   "source": [
    "#### Recompute returns given the new strategy: long during even years and short during odd years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eda3b52b-d82d-4947-ac16-f54552d53a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_short_df = dollar_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d75c958-0d00-4e6d-b86c-e927a7179b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_short_df['long_short_pos'] = np.where(long_short_df.datetime.dt.year % 2 == 0, 1, -1)\n",
    "long_short_df['long_short_returns'] = long_short_df.label_returns * long_short_df.long_short_pos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
